{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Questions"
      ],
      "metadata": {
        "id": "kl-R3lQSTBxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        " - A parameter is a measurable characteristic or fixed value that helps define or describe a system, situation, or population. In mathematics and statistics, a parameter usually refers to a numerical value that describes an entire group, such as the average (mean) height of all students in a school. Unlike a variable, which can change, a parameter is generally considered constant within a specific context. In programming, a parameter is a value that is passed into a function so that the function can use it to perform a specific task. Overall, a parameter sets the limits or conditions under which something operates or is analyzed.\n",
        "\n",
        " 2. What is correlation?\n",
        "   What does negative correlation mean?\n",
        "\n",
        "  - Correlation is a statistical concept that shows the relationship between two variables ‚Äî specifically, how they move in relation to each other.\n",
        "\n",
        "If one variable changes and the other also changes in a predictable way, they are said to be correlated.\n",
        "\n",
        "There are three main types of correlation:\n",
        "\n",
        "Positive Correlation ‚Äì When one variable increases, the other also increases.\n",
        "Example: As study time increases, marks often increase.\n",
        "\n",
        "Negative Correlation ‚Äì When one variable increases, the other decreases.\n",
        "Example: As speed increases, time taken to reach a destination decreases.\n",
        "\n",
        "Zero (No) Correlation ‚Äì When there is no relationship between the variables.\n",
        "Example: Shoe size and intelligence.\n",
        "Correlation is usually measured by a number called the correlation coefficient, which ranges from ‚Äì1 to +1:\n",
        "+1 ‚Üí Perfect positive correlation\n",
        "‚Äì1 ‚Üí Perfect negative correlation\n",
        "0 ‚Üí No correlation\n",
        "\n",
        "3. Define Machine Learning. What are the main components in    Machine Learning?\n",
        " - Definition of Machine Learning\n",
        "\n",
        "Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn from data and improve their performance without being explicitly programmed. Instead of following fixed instructions, a machine learning system identifies patterns in data and makes predictions or decisions based on those patterns.\n",
        "\n",
        "Main Components of Machine Learning\n",
        "\n",
        "Data\n",
        "Data is the most important component. It is used to train the model.\n",
        "\n",
        "It can be text, images, numbers, audio, etc.\n",
        "\n",
        "Good quality data improves accuracy.\n",
        "\n",
        "Features\n",
        "Features are the important characteristics or inputs taken from the data that help the model learn.\n",
        "Example: For predicting house prices, features may include size, location, number of rooms, etc.\n",
        "\n",
        "Model\n",
        "A model is the mathematical representation or algorithm that learns from data.\n",
        "Examples include:\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "Decision Tree\n",
        "\n",
        "Neural Network\n",
        "\n",
        "Training\n",
        "The process of feeding data into the model so it can learn patterns.\n",
        "\n",
        "Evaluation\n",
        "Checking how well the model performs using testing data and accuracy measures.\n",
        "\n",
        "Prediction (Inference)\n",
        "Using the trained model to make predictions on new, unseen data.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        " - How Loss Value Helps Determine if a Model is Good\n",
        "\n",
        "In Machine Learning, the loss value measures how far the model‚Äôs predictions are from the actual correct answers.\n",
        "\n",
        "It tells us how much error the model is making.\n",
        "\n",
        "üîπ What Does Loss Mean?\n",
        "\n",
        "Low loss value ‚Üí Predictions are close to actual values ‚Üí Model is performing well.\n",
        "\n",
        "High loss value ‚Üí Predictions are far from actual values ‚Üí Model is not performing well.\n",
        "\n",
        "So, the goal during training is to minimize the loss.\n",
        "\n",
        "üîπ How It Helps Judge the Model\n",
        "\n",
        "During Training\n",
        "\n",
        "If loss keeps decreasing, the model is learning correctly.\n",
        "\n",
        "If loss stops decreasing, learning may have stopped.\n",
        "\n",
        "If loss increases, something may be wrong (like overfitting or wrong learning rate).\n",
        "\n",
        "Comparing Models\n",
        "\n",
        "The model with lower loss (on test data) is usually better.\n",
        "\n",
        "Detecting Overfitting\n",
        "\n",
        "If training loss is very low but testing loss is high, the model is overfitting (memorizing instead of learning).\n",
        "\n",
        "üîπ Simple Example\n",
        "\n",
        "If a model predicts marks:\n",
        "\n",
        "Actual marks = 90\n",
        "\n",
        "Predicted marks = 88\n",
        "\n",
        "Error is small ‚Üí Loss is small ‚Üí Good model\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        " - 1. Continuous Variables\n",
        "A continuous variable is a variable that can take any value within a given range.\n",
        "It is usually measured using numbers and can include decimals.\n",
        "‚úÖ Examples:\n",
        "Height (170.5 cm, 165.2 cm)\n",
        "Weight (60.3 kg, 72.8 kg)\n",
        "Temperature (36.6¬∞C, 40.1¬∞C)\n",
        "Time (2.5 hours, 3.75 hours)\n",
        "üëâ Continuous variables are measurable and can have infinite possible values within a range.\n",
        "\n",
        "üîπ 2. Categorical Variables\n",
        "A categorical variable represents categories or groups instead of numerical measurements.\n",
        "\n",
        "‚úÖ Examples:\n",
        "Gender (Male, Female)\n",
        "Blood Group (A, B, AB, O)\n",
        "Color (Red, Blue, Green)\n",
        "Yes/No responses\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        " - In Machine Learning, categorical variables cannot be used directly because most algorithms work only with numerical data, so they must be converted into numbers before training the model. This process is called encoding. One common technique is Label Encoding, where each category is assigned a unique number. Another widely used method is One-Hot Encoding, which creates separate binary (0 or 1) columns for each category to avoid introducing any false order between them. When categories have a natural ranking, Ordinal Encoding is used to assign ordered numerical values. For datasets with many categories, techniques like Binary Encoding help reduce the number of columns created. In advanced cases, Target (Mean) Encoding replaces each category with the average value of the target variable for that category. Overall, the choice of technique depends on whether the categories have order and how many unique categories are present in the dataset.\n",
        "\n",
        " 7. What do you mean by training and testing a dataset?\n",
        "  - Training and testing a dataset are two important steps in Machine Learning used to build and evaluate a model.\n",
        "\n",
        "When we train a model, we give it a portion of the dataset called the training dataset. The model learns patterns, relationships, and rules from this data. It adjusts its internal parameters to minimize errors and improve accuracy. In simple words, training is the learning phase of the model.\n",
        "\n",
        "After training, we use another portion of the data called the testing dataset to check how well the model performs on new, unseen data. The testing data is not shown to the model during training. This step helps us evaluate the model‚Äôs accuracy and determine whether it has learned properly or is just memorizing the training data (overfitting).\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        " - sklearn.preprocessing is a module in the Python library scikit-learn that is used for data preprocessing before applying machine learning algorithms.\n",
        "\n",
        "Preprocessing means preparing raw data so that it can be properly used by machine learning models. Most models work better when the data is clean, scaled, and converted into numerical form.\n",
        "The sklearn.preprocessing module provides tools for tasks such as:\n",
        "Scaling features (e.g., StandardScaler, MinMaxScaler)\n",
        "Normalizing data\n",
        "Encoding categorical variables (e.g., LabelEncoder, OneHotEncoder)\n",
        "Binarizing data\n",
        "For example, if one feature has values between 0‚Äì1 and another has values between 0‚Äì10,000, scaling helps bring them to a similar range so that the model performs better.\n",
        "\n",
        "9. What is a Test set?\n",
        " - A test set is a portion of a dataset that is used to evaluate the performance of a machine learning model after it has been trained. It contains data that the model has never seen before during training. The purpose of the test set is to check how well the model can make predictions on new, unseen data.\n",
        "\n",
        "By testing the model on this separate dataset, we can measure its accuracy, error rate, or other performance metrics. This helps determine whether the model has truly learned patterns from the data or if it has simply memorized the training data (a problem called overfitting).\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        " - 1. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "In Python, we commonly split data using the train_test_split() function from the scikit-learn library.\n",
        "\n",
        "First, the dataset is divided into:\n",
        "\n",
        "Training set ‚Üí Used to train (fit) the model\n",
        "\n",
        "Testing set ‚Üí Used to evaluate the model\n",
        "\n",
        "Example steps:\n",
        "\n",
        "Import train_test_split from sklearn.model_selection\n",
        "\n",
        "Choose the test size (for example, 20% or 30%)\n",
        "\n",
        "Split the features (X) and target (y)\n",
        "\n",
        "Typically:\n",
        "\n",
        "70‚Äì80% data ‚Üí Training\n",
        "\n",
        "20‚Äì30% data ‚Üí Testing\n",
        "\n",
        "This ensures the model learns from one portion of data and is evaluated on unseen data.\n",
        "\n",
        " 2. How do you approach a Machine Learning problem?\n",
        "\n",
        "A systematic approach is very important. The general steps are:\n",
        "1Ô∏è‚É£ Understand the Problem\n",
        "Clearly define the objective (classification, regression, etc.).\n",
        "2Ô∏è‚É£ Collect and Understand Data\n",
        "Explore the dataset and understand features and target variables.\n",
        "3Ô∏è‚É£ Data Preprocessing\n",
        "Handle missing values\n",
        "Encode categorical variables\n",
        "Scale/normalize features\n",
        "4Ô∏è‚É£ Split the Data\n",
        "Divide into training and testing sets.\n",
        "5Ô∏è‚É£ Choose a Model\n",
        "Select an appropriate algorithm (e.g., regression, decision tree, etc.).\n",
        "6Ô∏è‚É£ Train the Model\n",
        "Fit the model using training data.\n",
        "7Ô∏è‚É£ Evaluate the Model\n",
        "Measure performance using metrics like accuracy, precision, recall, or mean squared error.\n",
        "8Ô∏è‚É£ Improve the Model\n",
        "Tune hyperparameters, try different models, or perform feature engineering.\n",
        "9Ô∏è‚É£ Deploy the Model (if required)\n",
        "Use the model in real-world applications.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        " - xploratory Data Analysis (EDA) is performed before fitting a model to understand the data properly and prepare it for accurate modeling. It helps us examine the structure, patterns, and quality of the dataset before applying any machine learning algorithm.\n",
        "\n",
        "EDA is important because it allows us to identify missing values, outliers, incorrect data types, and errors in the dataset. If these issues are not handled, the model may give poor or misleading results. It also helps us understand the relationship between variables, detect correlations, and decide which features are important for prediction.\n",
        "\n",
        "By visualizing and summarizing the data, we can choose the right preprocessing techniques (such as encoding or scaling) and select an appropriate model. Without EDA, we may apply the wrong algorithm or misinterpret the results.\n",
        "\n",
        "12. What is correlation?\n",
        " - Correlation is a statistical measure that shows the relationship between two variables, specifically how they move in relation to each other.\n",
        "If a change in one variable is associated with a change in another variable, the two variables are said to be correlated.\n",
        "There are three main types of correlation:\n",
        "Positive correlation: Both variables move in the same direction.\n",
        "(If one increases, the other also increases.)\n",
        "Negative correlation: Variables move in opposite directions.\n",
        "(If one increases, the other decreases.)\n",
        "Zero correlation: No relationship exists between the variables.\n",
        "Correlation is usually measured by a number called the correlation coefficient, which ranges from ‚Äì1 to +1:\n",
        "+1 ‚Üí Perfect positive correlation\n",
        "‚Äì1 ‚Üí Perfect negative correlation\n",
        "0 ‚Üí No correlation\n",
        "\n",
        "13. What does negative correlation mean?\n",
        " - Negative correlation means that two variables move in opposite directions.\n",
        "When one variable increases, the other decreases, and when one decreases, the other increases, the variables are said to have a negative correlation.\n",
        "\n",
        "For example:\n",
        "As price increases, demand decreases.\n",
        "As speed increases, time taken to travel a fixed distance decreases.\n",
        "In statistics, negative correlation is represented by a correlation coefficient between 0 and ‚Äì1.\n",
        "‚Äì1 indicates a perfect negative correlation.\n",
        "Values closer to ‚Äì1 show a strong negative relationship.\n",
        "Values closer to 0 show a weak negative relationship.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        " - You can find the correlation between variables in Python mainly using the pandas and NumPy libraries.\n",
        "\n",
        "The most common method is using the .corr() function in pandas. If your data is stored in a DataFrame, you can calculate the correlation between all numerical columns by simply writing:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "This will give you a correlation matrix, which shows the correlation coefficient between every pair of numerical variables. By default, it calculates Pearson correlation.\n",
        "\n",
        "If you want correlation between two specific variables, you can write:\n",
        "\n",
        "df[\"column1\"].corr(df[\"column2\"])\n",
        "\n",
        "Using NumPy, you can calculate correlation like this:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.corrcoef(x, y)\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        " - Causation refers to a relationship where one variable directly causes a change in another variable. It means there is a clear cause-and-effect connection between the two.\n",
        "\n",
        "The main difference between correlation and causation is that correlation only shows that two variables are related or move together, while causation shows that one variable actually produces an effect on the other. In correlation, variables may change together, but there is no proof that one is responsible for the change. In causation, the change in one variable is the direct reason for the change in the other.\n",
        "\n",
        "For example, during summer, ice cream sales and drowning cases both increase. These two are positively correlated because they rise at the same time. However, ice cream does not cause drowning. The real cause is hot weather, which increases both ice cream consumption and swimming activities. This is correlation, not causation.\n",
        "\n",
        "On the other hand, if a person increases their study time and their exam marks improve, the extra study time directly contributes to better performance. This is an example of causation.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example\n",
        " - What is an Optimizer?\n",
        "\n",
        "An optimizer is an algorithm used in Machine Learning and Deep Learning to minimize the loss function by updating the model‚Äôs parameters (weights and biases). Its main goal is to find the best values of parameters so that the model makes accurate predictions.\n",
        "During training, the optimizer adjusts the weights step-by-step to reduce error and improve performance.\n",
        "\n",
        "Types of Optimizers\n",
        "1Ô∏è‚É£ Gradient Descent\n",
        "This is the basic optimization algorithm. It updates weights in the direction of the negative gradient (the direction that reduces loss).\n",
        "\n",
        "Example:\n",
        "If the loss is high, gradient descent adjusts the weights slightly to reduce the error step-by-step.\n",
        "There are three types:\n",
        "Batch Gradient Descent\n",
        "Stochastic Gradient Descent (SGD)\n",
        "Mini-batch Gradient Descent\n",
        "\n",
        "2Ô∏è‚É£ Stochastic Gradient Descent (SGD)\n",
        "SGD updates the weights using one training example at a time.\n",
        "Example:\n",
        "If we have 1000 data points, SGD updates weights after each single data point instead of waiting for all 1000.\n",
        "\n",
        "‚úÖ Faster updates\n",
        "‚ö† More fluctuations in learning\n",
        "\n",
        "3Ô∏è‚É£ Momentum\n",
        "Momentum improves SGD by adding a fraction of the previous update to the current update. It helps move faster in the correct direction and reduces oscillations.\n",
        "Example:\n",
        "Like pushing a ball down a hill ‚Äî it gains speed in the correct direction.\n",
        "\n",
        "4Ô∏è‚É£ AdaGrad (Adaptive Gradient)\n",
        "AdaGrad adjusts the learning rate for each parameter automatically. Parameters with frequent updates get smaller learning rates.\n",
        "Example:\n",
        "Useful in text classification where some words appear more often than others.\n",
        "\n",
        "5Ô∏è‚É£ RMSProp\n",
        "RMSProp improves AdaGrad by preventing the learning rate from becoming too small. It works well for deep neural networks.\n",
        "\n",
        "6Ô∏è‚É£ Adam (Adaptive Moment Estimation)\n",
        "Adam combines the advantages of Momentum and RMSProp. It is one of the most widely used optimizers.\n",
        "Example:\n",
        "In deep learning tasks like image classification, Adam often converges faster and performs well.\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        " - sklearn.linear_model is a module in the Python machine learning library scikit-learn that provides algorithms based on linear models.\n",
        "\n",
        "Linear models assume a linear relationship between input features (independent variables) and the target variable (dependent variable). These models are commonly used for regression and classification tasks.\n",
        "\n",
        "üîπ What does it include?\n",
        "\n",
        "The sklearn.linear_model module contains popular algorithms such as:\n",
        "\n",
        "Linear Regression ‚Äì Used for predicting continuous values (e.g., house price prediction).\n",
        "\n",
        "Logistic Regression ‚Äì Used for classification problems (e.g., spam detection).\n",
        "\n",
        "Ridge Regression ‚Äì Linear regression with L2 regularization.\n",
        "\n",
        "Lasso Regression ‚Äì Linear regression with L1 regularization.\n",
        "\n",
        "ElasticNet ‚Äì Combination of Ridge and Lasso.\n",
        "\n",
        "üîπ Why is it important?\n",
        "\n",
        "Simple and easy to understand\n",
        "\n",
        "Fast to train\n",
        "\n",
        "Works well when the relationship between variables is approximately linear\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        " - What does model.fit() do?\n",
        "\n",
        "In Machine Learning (especially in scikit-learn), the model.fit() function is used to train the model on the given dataset.\n",
        "When we call model.fit(), the model:\n",
        "Learns patterns from the training data\n",
        "Adjusts its internal parameters (weights and bias)\n",
        "Minimizes the loss/error\n",
        "In simple words, fit() teaches the model using the training data.\n",
        "What arguments must be given?\n",
        "The basic syntax is:\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "Two main arguments are required:\n",
        "\n",
        "1Ô∏è‚É£ X (Features / Input data)\n",
        "Independent variables\n",
        "Usually a 2D array or DataFrame\n",
        "Example: size of house, number of rooms, etc.\n",
        "\n",
        "2Ô∏è‚É£ y (Target / Output data)\n",
        "Dependent variable\n",
        "Usually a 1D array or Series\n",
        "Example: house price\n",
        "\n",
        "üîπ Optional Arguments (in some models)\n",
        "Some models may also accept:\n",
        "sample_weight ‚Üí To give different importance to samples\n",
        "epochs, batch_size (in deep learning libraries like Keras)\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?What does model.predict() do?\n",
        "\n",
        "In Machine Learning (commonly using scikit-learn), the model.predict() function is used to make predictions using a trained model.\n",
        "\n",
        "After the model has been trained using model.fit(), we use model.predict() to:\n",
        "\n",
        "Generate predicted outputs\n",
        "\n",
        "Estimate target values for new, unseen data\n",
        "\n",
        "In simple words, predict() uses what the model has learned to give answers.\n",
        "\n",
        "What arguments must be given?\n",
        "\n",
        "Basic syntax:\n",
        "model.predict(X)\n",
        "It requires one main argument:\n",
        "\n",
        "üîπ X (Input Features)\n",
        "\n",
        "Independent variables\n",
        "Must have the same format and number of features as the training data\n",
        "Usually a 2D array or DataFrame\n",
        "Example:\n",
        "If the model was trained to predict house prices using features like size and number of rooms, then X should contain those same features for new houses.\n",
        "\n",
        "üîπ What does it return?\n",
        "For regression ‚Üí Predicted numerical values\n",
        "For classification ‚Üí Predicted class labels\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        " - Continuous and categorical variables are two main types of variables used in statistics and machine learning.\n",
        "\n",
        "A continuous variable is a numerical variable that can take any value within a given range. It is measurable and can include decimal or fractional values. For example, height (170.5 cm), weight (65.2 kg), temperature (36.7¬∞C), and time (2.5 hours) are continuous variables because they can take infinitely many possible values within a range.\n",
        "\n",
        "A categorical variable, on the other hand, represents categories or groups rather than numerical measurements. It describes qualities or labels. Examples include gender (Male/Female), blood group (A, B, AB, O), color (Red, Blue, Green), and yes/no responses. These variables do not represent quantities but classifications.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        " - What is Feature Scaling?\n",
        "\n",
        "Feature scaling is the process of adjusting the range of numerical features so that they are on a similar scale. In many datasets, different features may have very different ranges. For example, age might range from 1 to 100, while income might range from 10,000 to 1,000,000. Feature scaling brings these values to a comparable range.\n",
        "\n",
        "Common Feature Scaling Methods\n",
        "\n",
        "1Ô∏è‚É£ Standardization (Z-score Normalization)\n",
        "Transforms data so that it has:\n",
        "Mean = 0\n",
        "Standard deviation = 1\n",
        "2Ô∏è‚É£ Min-Max Scaling (Normalization)\n",
        "Scales values between 0 and 1 using a formula.\n",
        "These methods are commonly available in scikit-learn under preprocessing tools.\n",
        "\n",
        "How Does It Help in Machine Learning?\n",
        "\n",
        "Feature scaling helps because:\n",
        "‚úÖ It prevents features with large values from dominating the model.\n",
        "‚úÖ It improves the speed of convergence in optimization algorithms (like gradient descent).\n",
        "‚úÖ It improves the performance of distance-based algorithms like KNN and clustering.\n",
        "‚úÖ It makes model training more stable and efficient.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        " - We perform feature scaling in Python mainly using the preprocessing tools from scikit-learn.\n",
        "The most commonly used scaling methods are:\n",
        "üîπ 1Ô∏è‚É£ Standardization (StandardScaler)\n",
        "This method transforms the data so that:\n",
        "Mean = 0\n",
        "Standard deviation = 1\n",
        "Example:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "fit() ‚Üí Calculates mean and standard deviation\n",
        "transform() ‚Üí Applies scaling\n",
        "fit_transform() ‚Üí Does both steps together\n",
        "\n",
        "üîπ 2Ô∏è‚É£ Min-Max Scaling (MinMaxScaler)\n",
        "This scales values between 0 and 1.\n",
        "Example:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "üîπ Important Practice\n",
        "When splitting data into training and testing sets:\n",
        "Fit the scaler only on the training data\n",
        "Then transform both training and testing data\n",
        "Example:\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        " - sklearn.preprocessing is a module in the Python machine learning library scikit-learn that is used to prepare and transform raw data before training a model.\n",
        "\n",
        "In Machine Learning, data often needs cleaning and transformation because algorithms work best with properly formatted numerical inputs. The sklearn.preprocessing module provides tools to handle this preparation step.\n",
        "\n",
        "It includes methods for:\n",
        "\n",
        "Feature scaling (e.g., StandardScaler, MinMaxScaler)\n",
        "\n",
        "Encoding categorical variables (e.g., LabelEncoder, OneHotEncoder)\n",
        "\n",
        "Normalizing data\n",
        "\n",
        "Binarizing features\n",
        "\n",
        "For example, if one feature has values in thousands and another in decimals, scaling ensures they are on a similar range. If a column contains categories like ‚ÄúMale‚Äù and ‚ÄúFemale,‚Äù encoding converts them into numerical form.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        " - To split data for model fitting (training and testing) in Python, we commonly use the train_test_split() function from scikit-learn.\n",
        "\n",
        "First, we separate the dataset into:\n",
        "\n",
        "X (features / independent variables)\n",
        "\n",
        "y (target / dependent variable)\n",
        "\n",
        "Then we split the data into training and testing sets. The training set is used to train the model, and the testing set is used to evaluate its performance on unseen data.\n",
        "\n",
        "Example:\n",
        " from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "25. Explain data encoding?\n",
        " - Data Encoding\n",
        "\n",
        "Data encoding is the process of converting categorical (text) data into numerical form so that machine learning models can understand and process it. Most machine learning algorithms work only with numbers, so categories like ‚ÄúMale/Female‚Äù or ‚ÄúRed/Blue/Green‚Äù must be converted into numerical values before training the model.\n",
        "\n",
        "üîπ Why is Data Encoding Needed?\n",
        "\n",
        "Computers cannot directly understand text labels. For example:\n",
        "\n",
        "Gender ‚Üí Male, Female\n",
        "\n",
        "City ‚Üí Delhi, Mumbai, Chennai\n",
        "\n",
        "These must be transformed into numbers so the model can perform calculations.\n",
        "\n",
        "üîπ Common Encoding Techniques\n",
        "\n",
        "1Ô∏è‚É£ Label Encoding\n",
        "Each category is assigned a unique number.\n",
        "Example:\n",
        "Red ‚Üí 0\n",
        "Blue ‚Üí 1\n",
        "Green ‚Üí 2\n",
        "\n",
        "2Ô∏è‚É£ One-Hot Encoding\n",
        "Creates separate columns for each category and uses 0 or 1 to indicate presence.\n",
        "\n",
        "3Ô∏è‚É£ Ordinal Encoding\n",
        "Used when categories have a meaningful order.\n",
        "Example:\n",
        "\n",
        "Low ‚Üí 1\n",
        "\n",
        "Medium ‚Üí 2\n",
        "\n",
        "High ‚Üí 3\n",
        "\n",
        "üîπ Tools Used in Python\n",
        "Data encoding is commonly done using the preprocessing module of scikit-learn, such as:\n",
        "LabelEncoder\n",
        "OneHotEncoder"
      ],
      "metadata": {
        "id": "2vsa_zOPTGPq"
      }
    }
  ]
}